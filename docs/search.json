[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction\nThis is the learning diary of the CASA0023 (Remotely Sensing Cities and Environments)."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n2  Introduction\n",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bailey, J. et al. (2023) ‘Localizing SDG\n11.6.2 via Earth Observation, Modelling\nApplications, and Harmonised City Definitions:\nPolicy Implications on Addressing Air\nPollution’, Remote Sensing, 15(4), p. 1082. doi:\n10.3390/rs15041082.\n\n\nChen, C. et al. (2019) ‘Coastline information extraction\nbased on the tasseled cap transformation of Landsat-8 OLI\nimages’, Estuarine, Coastal and Shelf Science, 217, pp.\n281–291. doi: 10.1016/j.ecss.2018.10.021.\n\n\nChen, C. et al. (2020) ‘The method for water body\ninformation extraction in complex environment using GF-1\nWFV images’, E3S Web of Conferences, 213, p.\n03024. doi: 10.1051/e3sconf/202021303024.\n\n\nChen, C. et al. (2022) ‘Extraction of Water Body\nInformation from Remote Sensing Imagery While Considering\nGreenness and Wetness Based on Tasseled Cap\nTransformation’, Remote Sensing, 14(13), p. 3001.\ndoi: 10.3390/rs14133001.\n\n\nCosta, A. da S., Lameira, O. A. and Costa, D. L. C. (2023) ‘The\nuse of NDVI derived from Pléiade images in the analysis of the\nvegetation structure in two forest fragments’, Seven\nEditora. Available at: https://sevenpublicacoes.com.br/index.php/editora/article/view/984\n(Accessed: 3 March 2024).\n\n\nDai, H. (2023) ‘Application of PCA Numalgorithm in\nRemote Sensing Image Processing’, Modern\nElectronic Technology, 7(1), pp. 17–21. doi: 10.26549/met.v7i1.12317.\n\n\nDanek, T., Weglinska, E. and Zareba, M. (2022) ‘The influence of\nmeteorological factors and terrain on air pollution concentration and\nmigration: A geostatistical case study from Krakow,\nPoland’, Scientific Reports, 12(1), p.\n11050. doi: 10.1038/s41598-022-15160-3.\n\n\nEisfelder, C. et al. (2023) ‘Seasonal Vegetation\nTrends for Europe over 30 Years from a\nNovel Normalised Difference Vegetation Index\n(NDVI) Time-Series—The TIMELINE NDVI\nProduct’, Remote Sensing, 15(14), p. 3616. doi:\n10.3390/rs15143616.\n\n\nEnvironment, U. N. (Fri, 09/03/2021 - 10:01) ‘Actions on Air\nQuality: A Global Summary of Policies\nand Programmes to Reduce Air\nPollution’, UNEP - UN Environment Programme.\nAvailable at: http://www.unep.org/resources/report/actions-air-quality-global-summary-policies-and-programmes-reduce-air-pollution\n(Accessed: 3 March 2024).\n\n\nEnvironment, U. N. (Sun, 01/31/2016 - 00:00) ‘Actions on Air\nQuality’, UNEP - UN Environment Programme.\nAvailable at: http://www.unep.org/resources/assessment/actions-air-quality\n(Accessed: 3 March 2024).\n\n\nGreenfield, D. E. (2023) ‘New York Air Quality:\nChallenges And Solutions’, Sigma Earth.\nAvailable at: https://sigmaearth.com/new-york-air-quality-challenges-and-solutions/\n(Accessed: 3 March 2024).\n\n\nJamal Jumaah, H. et al. (2023) ‘Air Pollution Risk\nAssessment Using GIS and Remotely Sensed Data in\nKirkuk City, Iraq’, Journal of\nAtmospheric Science Research, 6(3), pp. 41–51. doi: 10.30564/jasr.v6i3.5834.\n\n\nJensen, J. R. (2015) Introductory Digital Image\nProcessing: A Remote Sensing Perspective. 4th\nedn. USA: Prentice Hall Press.\n\n\nLiu, Q. (2019a) ‘A tasseled cap transformation for\nCBERS-04 fusion multispectral images’, in\nEleventh International Conference on Digital\nImage Processing (ICDIP 2019). SPIE, pp.\n730–736. doi: 10.1117/12.2539649.\n\n\nLiu, Q. (2019b) ‘A Tasseled Cap Transformation for\nGF-2 Fused Multispectral Images’, in 2019 12th\nInternational Congress on Image and\nSignal Processing, BioMedical Engineering and\nInformatics (CISP-BMEI), pp. 1–5. doi: 10.1109/CISP-BMEI48845.2019.8966053.\n\n\nLiu, Q. and Liu, G. (2009) ‘Using Tasseled Cap\nTransformation of CBERS-02 Images to Detect\nDieback or Dead Robinia Pseudoacacia\nPlantation’, in 2009 2nd International\nCongress on Image and Signal\nProcessing, pp. 1–5. doi: 10.1109/CISP.2009.5304005.\n\n\nMishra, R. et al. (2023) ‘Remote Sensing Image\nFusion Based on PCA and\nWavelets’, in Bhateja, V. et al. (eds)\nIntelligent Data Engineering and\nAnalytics. Singapore: Springer Nature (Smart\nInnovation, Systems and\nTechnologies), pp. 25–33. doi: 10.1007/978-981-19-7524-0_3.\n\n\nNew York City Comptroller (n/d) ‘Emissions’, Office of\nthe New York City Comptroller Brad Lander. Available at: https://comptroller.nyc.gov/services/for-the-public/nyc-climate-dashboard/emissions/\n(Accessed: 4 March 2024).\n\n\nNew York City’s climate team (n/d) ‘OneNYC\n2050’, NYC Mayor’s Office of Climate and Environmental\nJustice. Available at: https://climate.cityofnewyork.us/reports/onenyc-2050/\n(Accessed: 3 March 2024).\n\n\nPriya, M. V. et al. (2023) ‘Monitoring vegetation\ndynamics using multi-temporal NDVI and EVI\nimages for different agro climatic zones of Tamil\nNadu’. doi: 10.21203/rs.3.rs-2967925/v1.\n\n\nStankova, N. and Avetisyan, D. (2023) ‘Modeling post-fire forest\nregrowth using tasseled cap-derived indicators’, in Schulz, K.,\nNikolakopoulos, K. G., and Michel, U. (eds) Earth\nResources and Environmental Remote\nSensing/GIS Applications XIV. Amsterdam,\nNetherlands: SPIE, p. 54. doi: 10.1117/12.2679783.\n\n\nStoyanov, A. (2022) ‘Application of Tasseled Cap\nTransformation of Sentinel-2—MSI Data\nfor Forest Monitoring and Change Detection on\nTerritory of Natural Park “BLUE\nSTONES”’, Environmental Sciences\nProceedings, 22(1), p. 42. doi: 10.3390/IECF2022-13073.\n\n\nSukawattanavijit, C. et al. (2023) ‘The future of urban\nair quality management in Thailand: The cutting-edge\nplatform for monitoring and management of public health and sustainable\ndevelopment’, in Chrysoulakis, N., Erbertseder, T., and Zhang, Y.\n(eds) Remote Sensing Technologies and\nApplications in Urban Environments VIII.\nAmsterdam, Netherlands: SPIE, p. 19. doi: 10.1117/12.2679297.\n\n\nThe Nature Conservancy (n/d) ‘What is Remote Sensing?\n Reef Resilience’. Available at: https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/\n(Accessed: 3 February 2024).\n\n\nWang, K. and Zhu, Y. (2003) ‘Recognition of Water\nBodies from Remotely Sensed Imagery by Using\nNeural Network’, in. Available at: https://www.semanticscholar.org/paper/Recognition-of-Water-Bodies-from-Remotely-Sensed-by-Wang-Zhu/e9bfbfb9b558e0fccb5f49a51fdc24d558bef220\n(Accessed: 3 March 2024).\n\n\nWorld Health Organization (n/d) ‘WHO\nGuidelines’. Available at: https://www.who.int/publications/who-guidelines\n(Accessed: 3 March 2024).\n\n\nZhuang, Y. and Chen, C. (2018) ‘A Method for water\nbody extraction based on the tasselled cap transformation from remote\nsensing images’, in 2018 Fifth International\nWorkshop on Earth Observation and Remote\nSensing Applications (EORSA), pp. 1–5. doi: 10.1109/EORSA.2018.8598605."
  },
  {
    "objectID": "Week_2.html#presentation",
    "href": "Week_2.html#presentation",
    "title": "\n2  Week 2 - Portfolio tools: Quarto\n",
    "section": "\n2.1 Presentation",
    "text": "2.1 Presentation"
  },
  {
    "objectID": "Week_1.html#summary",
    "href": "Week_1.html#summary",
    "title": "1  Week 1 - An Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThis section will summarize the content of first week of remote sensing course, which is some basic remote sensing knowledge, including how to obtain remote sensing images, image features, etc. Some key points are listed below.\n\n1.1.1 Overview of remote sensing\nRemote sensing is a technology that senses and measures information on the earth’s surface over long distances. It is now frequently used to obtain accurate and timely information, and most remote sensing data are analyzed using digital image processing techniques (Jensen, 2015).\n\n\n1.1.2 Sensor types\n\nPassive: Receive energy reflected from the sun\nActive: Actively emits electromagnetic waves and then waits to receive\n\n\n\n\nDifference between passive and active sensors (The Nature Conservancy, n/d)\n\n\n\n\n1.1.3 Electromagnetic radiation(EMR) interacts with Earth’s surface\nEnergy can be absorbed and transmitted.\nTwo forms:\n\nSurface scattering\nAtmospheric scattering\n\n\n\n1.1.4 Big issue caused by scattering\n\n1.1.4.1 Problem\nClouds: Impact on remote sensing applications\n\n\n1.1.4.2 Solution\nSynthetic Aperture Radar (SAR)\n\nIt is an active microwave remote sensing technology\nIt is not limited by weather conditions, cloud cover, or nighttime\nValuable for geological exploration, land use monitoring, disaster assessment\n\n\n\n1.1.4.3 Conclusion\nThe sun’s energy interacts with the Earth’s surface in many ways, affecting the creation and use of data.\n\n\n\n1.1.5 Remote sensing data\n\n1.1.5.1 Data formats\n\nData format: Raster\nCommon data storage format: GeoTIFF\n\n\n\n1.1.5.2 Data resolution\n\nSpatial: The size of the raster cells\nSpectral: The number of bands, and each band is usually provided as a separate raster layer\nTemporal: The revisit time of the sensor\nRadiometric: The ability of a sensor to identify and show small differences in energy\n\n\n\n\n1.1.6 How to select data\n\nEnvironmental constraints\n\nResearch area\nResearch question\nresearch Fund (cost)\n…\n\nSensor constraints\n\nSize of features\nSpectral sensitivity\nDate range\nQuality of the image\nType of orbit\n…\n\n\n\n\n1.1.7 Practical\n\n1.1.7.1 Use Tasseled Cap transformation for analysis\n\nTasseled Cap function\n\n\\[\n\\begin{split}\nBrightness = 0.3037(B2)+0.2793(B3)+\\\\0.4743(B4)+0.5585(B8)+\\\\\n0.5082(B11)+0.1863(B12)\n\\end{split}\n\\]\n\\[\n\\begin{split}\nGreeness = −0.2848(B2)−0.2435(B3)\\\\−0.5436(B4)+0.7243(B8)+\\\\\n0.0840(B11)−0.1800(B12)\n\\end{split}\n\\]\n\\[\n\\begin{split}\nWetness = 0.1509(B2)+0.1973(B3)\\\\+0.3279(B4)+0.3406(B8)\\\\−\n0.7112(B11)−0.4572(B12)\n\\end{split}\n\\]\n\nMasking and resampling\n\n\nResample bands 2,3,4 and 8 to 20m\nClip the raster to the City of Capetown polygon\n\n\nResult\n\n\n\n\nTasseled Cap transformation result\n\n\nIt can be found from the figure:\n\nBrightness reflects bare soil, artificial surfaces, bright materials\nGreenness reflects green vegetation\nWetness reflects moisture\n\n\n\n1.1.7.2 Spectral signatures of POIs\nLand cover types of POIs:\n\nBare earth\ngrass\nForest\nHigher reflective urban\nLower reflective urban\n\n\n\n\nA: Line graph of spectral characteristics B: Density distribution plot of spectral features\n\n\nIt can be seen from the results that different POIs have different performances on different bands, and high urban has a larger difference than other POIs. Specific areas can be detected or classified through differences in band values in different areas, or by combining the values of several bands."
  },
  {
    "objectID": "Week_1.html#applications",
    "href": "Week_1.html#applications",
    "title": "1  Week 1 - An Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nIn the first week of study, I am most interested in Tasseled Cap transformation (TCT). It converts spectral information in remote sensing images into brightness, greenness, and wetness components, which can be applied in many fields.\nSpecifically, TCT can help extract water bodies by obtaining the greenness and wetness components of remote sensing images, and can reduce the impact of shadows, dense vegetation and buildings (Zhuang and Chen, 2018; Chen et al., 2020, 2022). By considering the characteristics of coastline morphology and the greenness and wetness components, the TCT can also be used to extract coastline information, particularly in areas with high sediment concentration (Chen et al., 2019).One study (Wang and Zhu, 2003) compared the TCT method with a Learning Vector Quantization (LVQ) neural network and a conventional rule-based method for water body extraction from Landsat 4 satellite images. It was found that the error of thresholding on the wetness in the TCT method is too large to be practical for this purpose. This suggests that while TCT can be useful for various remote sensing applications, its effectiveness for water body extraction may be limited under certain conditions or compared to other specialized methods.\nComponents of TCT, such as brightness, greenness, and wetness, can provide valuable information about the condition and changes in forest vegetation over time (Liu, 2019b, 2019a; Stoyanov, 2022), also monitor the health of the forest (Liu and Liu, 2009). But the TCT parameters need to be recalculated for different sensors or spectral data, enabling more accurate classification of vegetation patches, crop types, and changes in forest health. Moreover, an innovative approach involved modeling post-fire forest regrowth using TCT-derived indicators (Stankova and Avetisyan, 2023). This methodology leverages the TCT to increase the identification of components (soil, vegetation, and moisture) changing during a fire, thereby providing a cost-effective tool for monitoring the recovery of burnt forests."
  },
  {
    "objectID": "Week_1.html#reflections",
    "href": "Week_1.html#reflections",
    "title": "1  Week 1 - An Introduction to Remote Sensing",
    "section": "1.3 Reflections",
    "text": "1.3 Reflections\nOverall, the first week was heavy and covered many basic concepts of remote sensing data, but it was not difficult in terms of understanding. These basics were important to me as a beginner in remote sensing because it gave me a clear understanding of the sources and structure of remotely sensed data and laid the foundation for subsequent courses. Although I was a bit overwhelmed when I first came across SNAP as a software, with a little bit of research on remote sensing data, I successfully used SNAP to get satisfactory analysis results. In addition, thanks to the emergence of packages such as stars and terra, it is easier and faster to analyse a large amount of remote sensing data in a unified way using R language, and the results can be presented in a more beautiful way. Therefore, for me personally, I prefer to use R for analyses.\n\n\n\n\nChen, C. et al. (2019) “Coastline information extraction based on the tasseled cap transformation of Landsat-8 OLI images,” Estuarine, Coastal and Shelf Science, 217, pp. 281–291. doi: 10.1016/j.ecss.2018.10.021.\n\n\nChen, C. et al. (2020) “The method for water body information extraction in complex environment using GF-1 WFV images,” E3S Web of Conferences, 213, p. 03024. doi: 10.1051/e3sconf/202021303024.\n\n\nChen, C. et al. (2022) “Extraction of Water Body Information from Remote Sensing Imagery While Considering Greenness and Wetness Based on Tasseled Cap Transformation,” Remote Sensing, 14(13), p. 3001. doi: 10.3390/rs14133001.\n\n\nJensen, J. R. (2015) Introductory Digital Image Processing: A Remote Sensing Perspective. 4th ed. USA: Prentice Hall Press.\n\n\nLiu, Q. (2019a) “A tasseled cap transformation for CBERS-04 fusion multispectral images,” in Eleventh International Conference on Digital Image Processing (ICDIP 2019). SPIE, pp. 730–736. doi: 10.1117/12.2539649.\n\n\nLiu, Q. (2019b) “A Tasseled Cap Transformation for GF-2 Fused Multispectral Images,” in 2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI), pp. 1–5. doi: 10.1109/CISP-BMEI48845.2019.8966053.\n\n\nLiu, Q. and Liu, G. (2009) “Using Tasseled Cap Transformation of CBERS-02 Images to Detect Dieback or Dead Robinia Pseudoacacia Plantation,” in 2009 2nd International Congress on Image and Signal Processing, pp. 1–5. doi: 10.1109/CISP.2009.5304005.\n\n\nStankova, N. and Avetisyan, D. (2023) “Modeling post-fire forest regrowth using tasseled cap-derived indicators,” in Schulz, K., Nikolakopoulos, K. G., and Michel, U. (eds.) Earth Resources and Environmental Remote Sensing/GIS Applications XIV. Amsterdam, Netherlands: SPIE, p. 54. doi: 10.1117/12.2679783.\n\n\nStoyanov, A. (2022) “Application of Tasseled Cap Transformation of Sentinel-2—MSI Data for Forest Monitoring and Change Detection on Territory of Natural Park ‘BLUE STONES’,” Environmental Sciences Proceedings, 22(1), p. 42. doi: 10.3390/IECF2022-13073.\n\n\nThe Nature Conservancy (n/d) “What is Remote Sensing?  Reef Resilience.” Available at: https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/ (Accessed: February 3, 2024).\n\n\nWang, K. and Zhu, Y. (2003) “Recognition of Water Bodies from Remotely Sensed Imagery by Using Neural Network,” in. Available at: https://www.semanticscholar.org/paper/Recognition-of-Water-Bodies-from-Remotely-Sensed-by-Wang-Zhu/e9bfbfb9b558e0fccb5f49a51fdc24d558bef220 (Accessed: March 3, 2024).\n\n\nZhuang, Y. and Chen, C. (2018) “A Method for water body extraction based on the tasselled cap transformation from remote sensing images,” in 2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA), pp. 1–5. doi: 10.1109/EORSA.2018.8598605."
  },
  {
    "objectID": "references.html#section",
    "href": "references.html#section",
    "title": "References",
    "section": "",
    "text": "Jensen, J. R. (2015) Introductory digital image processing: A remote\nsensing perspective. 4th edn. USA: Prentice Hall Press.\n\n\nThe Nature Conservancy (n/d) ‘What is Remote Sensing?\n Reef Resilience’. Available at: https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/\n(Accessed: 3 February 2024)."
  },
  {
    "objectID": "Week_3.html#summary",
    "href": "Week_3.html#summary",
    "title": "3  Week 3 - Remote sensing data",
    "section": "3.1 Summary",
    "text": "3.1 Summary\nThis week’s content is very varied and covers the aspects of corrections, data joining and data enhancement. These operations are necessary, but there are many ways to implement them, and need to be flexible in choosing the method according to the specific problem. The following is a summary of some of the highlights.\n\n3.1.1 Corrections\n\n3.1.1.1 Geometric correction\nTwo ways modelling:\n\nInput to output (forward mapping)\nOutput to input (backward mapping)\n\nWe usually use backward mapping, because every value in the output pixel can get a value in the original input image.\n\n\n3.1.1.2 Atmospheric correction\n\nDark object subtraction (DOS) or histogram adjustment\nPsuedo-invariant Features (PIFs)\nChange digital brightness values into scaled surface reflectance.\nEmpirical line correction\n\n\n\n3.1.1.3 Orthorectification correction / topographic correction\n\nA subset of georectification\nRemoving distortions\nAtmospheric correction happens before topographic correction\n\n\n\n3.1.1.4 Radiometric calibration\n\nSensors capture image brightness and distributed as a Digital Number (DN, and no units)\nRadiometric calibration = DN to spectral radiance\n\n\n\n3.1.1.5 Analysis ready data (ARD)\nRemote sensing data has been corrected (like Landsat data).\n\n\n\n3.1.2 Data joining and enhancement\n\n3.1.2.1 Joining data sets\n“Mosaicking” in remote sensing: feather the images together to create a seamless mosaic or image.\n\n\n3.1.2.2 Image enhancement\n\nContrast enhancement methods (only applied to digital numbers)\n\nMinimum - Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nBand ratioing methods\n\nNDVI\nTasselled cap\nNormalized Burn Ratio\n\nFiltering\n\nLow pass filter (averages the surrounding pixels)\nHigh pass filter (enhance local variations)\nEdge enhancement (image sharpening)\n\nPrincipal component (dimensionatliy reduction)\nTexture (spatial variation of gray values)\nFusion\n\n\n\n\n3.1.3 Practical\nI focused on the data enhancement part of this week’s exercise, and here are some of the results of the experiment.\n\n3.1.3.1 The Normalised Difference Vegetation Index (NDVI)\nThe Normalized Difference Vegetation Index (NDVI) is a widely used vegetation index derived from satellite images. Plants have a unique reflectance characteristic, they reflect more near-infrared (NIR) light and absorb more visible light. When plants are healthy, they have a high chlorophyll content, which allows them to absorb more light in the red region of the spectrum and reflect more light in the NIR region. So NDVI uses this characteristic of plants to differentiate healthy vegetation from non-vegetation or unhealthy vegetation. The formula is as follows:\n\\[\nNDVI = \\frac{NIR-Red}{NIR+Red}\n\\]\nThe figure below shows the NDVI results for the northern part of Cape Town.\n\n\n\nNDVI result for north of Cape Town\n\n\nAreas with NDVI values greater than or equal to 0.2 were extracted. From the figure, it can be observed that the vegetation cover is concentrated in the south-eastern part of the country, while the north-western part of the country has very little vegetation cover.\n\n\n\nNDVI result for north of Cape Town (values above or equal to 0.2)\n\n\n\n\n3.1.3.2 Principal Component Analysis (PCA)\nPCA identifies duplicate data over multiple channels, reduces redundancy, and speeds up the processing time. It is useful to run the principal component analysis on multiple bands, as we found that the latter components did not contain more useful information. Most of the variance (eigenvalues) lies in principal components 1, 2 and 3, then only these three principal components need to be used.\n\nPCA numerical result for north of Cape Town\n\n\n\n\n\n\n\n\n\n\n\n\n\nComponents:\nPC1\nPC2\nPC3\nPC4\nPC5\nPC6\nPC7\nPC8\n\n\n\n\nStandard deviation\n2.655\n0.71471\n0.47307\n0.3667\n0.24626\n0.10550\n0.08700\n0.05873\n\n\nProportion of Variance 0.881\n0.881\n0.06385\n0.02797\n0.0168\n0.00758\n0.00139\n0.00095\n0.00043\n\n\nCumulative Proportion\n0.881\n0.94487\n0.97285\n0.9897\n0.99723\n0.99862\n0.99957\n1.00000\n\n\n\n\n\n\nImage mapping result of PCA for north of Cape Town"
  },
  {
    "objectID": "Week_3.html#applications",
    "href": "Week_3.html#applications",
    "title": "3  Week 3 - Remote sensing data",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nThis week’s application focuses on the NDVI and PCA sections, where a great deal of research exists and I will be looking for topics of interest to discuss.\n\n3.2.1 NDVI\nA study (Eisfelder et al., 2023) used satellite imagery to observe changes in plant growth in Europe and North Africa over a 30-year period. They used the NDVI index to measure plant growth, comparing the amount of light absorbed and reflected by plants. However, sometimes cloud cover can affect the NDVI results. And the study looks at changes over a long period of time, but may not capture the rapid changes that occur from one year to the next. In addition, the NDVI index may not be applicable to all types of plants.\nAnother study (Priya et al., 2023) used satellite imagery from 2011 to 2021 to track how Tamil Nadu’s plants and trees have changed over time. The researchers used two main tools, NDVI and enhanced vegetation index (EVI). However studies using NDVI and EVI may equally face problems such as cloud cover affecting the quality of satellite images, which may lead to inaccurate vegetation assessment. And the resolution of MODIS data at 250 metres may not capture small-scale vegetation changes, which may be important for understanding local agricultural practices or small forested areas. In addition, the study was limited to 11 years, which may not be sufficient to understand long-term vegetation dynamics or the effects of climate change on vegetation patterns.\nIn addition to this, there is a study (Costa, Lameira and Costa, 2023) that uses high-resolution Pléiades satellite images with four spectral bands to analyse the structure of vegetation and uses a vegetation index called NDVI to help monitor Brazilian vegetation, with denser vegetation having higher NDVI values. But the study only covers two forest fragments, which may not be representative of Brazil’s diverse forest ecosystems, limiting the generalisability of the results. It uses NDVI values derived from Pléiades imagery at a spatial resolution of 2 metres, which may not capture very small patterns or changes in vegetation. And there is no mention of comparisons with ground truth or other satellite data to validate NDVI results from Pléiades imagery.\n\n\n3.2.2 PCA\nOne study (Dai, 2023) used PCA to process images taken by satellites, including reducing the size of colour satellite images, reducing unwanted random patterns or “noise” in those images and combining different types of satellite images to obtain more information. However, this study does not mention the computational resources required for PCA, which could be important and affect its usefulness for some users. And there is no comparison of PCA with other image processing techniques.\nAnd a study (Mishra et al., 2023) used PCA to identify and extract the most important features in low-resolution multispectral (LRMS) images and combined it with image enhancement techniques to obtain higher-quality images for uses such as agriculture and security. However, the method may affect the quality of remote sensing images under different environmental conditions. Also the computational complexity of the method is not discussed, which is crucial for practical applications where processing time is a factor. In addition, the potential loss of information may occur in the spatial or spectral domain, which is also an aspect that needs to be considered in the method."
  },
  {
    "objectID": "Week_3.html#reflections",
    "href": "Week_3.html#reflections",
    "title": "3  Week 3 - Remote sensing data",
    "section": "3.3 Reflections",
    "text": "3.3 Reflections\nOnce again, I lament the fact that this week covered a lot of remote sensing and was more theoretical, due to the calibration aspect. While in practice, these theoretical formulas are yet easy to use in R, but take a while to run. What was really difficult was the texture analysis, which is such a computationally intensive task that it took a long, long time to perform. Cropping out smaller study areas is a better way to deal with this, or using Google Earth Engine.\nThis week I delved into both NDVI and PCA. Although the formula for NDVI seems relatively simple, it needs to be adjusted for different satellite data. It is a simple but effective way to get a good idea of the vegetation cover in an area. As for PCA, it is perfect for dealing with remotely sensed data that has many dimensions, thus showing which aspect of the data is crucial, and researchers can therefore focus more on the important parts of the data.\nBy studying this week’s content, I have learnt what appropriate methods should need to be applied in order to deal with different problems (calibration to data connectivity to data enhancement problems). Although many of the methods were not all practised due to time, this at least provided me with an idea of how to solve the problem.\n\n\n\n\nCosta, A. da S., Lameira, O. A. and Costa, D. L. C. (2023) “The use of NDVI derived from Pléiade images in the analysis of the vegetation structure in two forest fragments,” Seven Editora. Available at: https://sevenpublicacoes.com.br/index.php/editora/article/view/984 (Accessed: March 3, 2024).\n\n\nDai, H. (2023) “Application of PCA Numalgorithm in Remote Sensing Image Processing,” Modern Electronic Technology, 7(1), pp. 17–21. doi: 10.26549/met.v7i1.12317.\n\n\nEisfelder, C. et al. (2023) “Seasonal Vegetation Trends for Europe over 30 Years from a Novel Normalised Difference Vegetation Index (NDVI) Time-Series—The TIMELINE NDVI Product,” Remote Sensing, 15(14), p. 3616. doi: 10.3390/rs15143616.\n\n\nMishra, R. et al. (2023) “Remote Sensing Image Fusion Based on PCA and Wavelets,” in Bhateja, V. et al. (eds.) Intelligent Data Engineering and Analytics. Singapore: Springer Nature (Smart Innovation, Systems and Technologies), pp. 25–33. doi: 10.1007/978-981-19-7524-0_3.\n\n\nPriya, M. V. et al. (2023) “Monitoring vegetation dynamics using multi-temporal NDVI and EVI images for different agro climatic zones of Tamil Nadu.” doi: 10.21203/rs.3.rs-2967925/v1."
  },
  {
    "objectID": "Week_4.html#summary",
    "href": "Week_4.html#summary",
    "title": "4  Week 4 - Policy applications",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nNew York City faces significant air pollution challenges due to its dense population, extensive transportation network, and various industrial activities (Greenfield, 2023). The city’s air quality is impacted by emissions from vehicles, power plants, construction sites, and other sources.\n\n\n\nAnnual Greenhouse Gas Emissions (New York City Comptroller, n/d)\n\n\nThe high population density and traffic congestion in New York City result in elevated levels of vehicle emissions, especially in areas with heavy traffic. Industrial activities and commercial buildings also release pollutants into the air. These factors combined with geographical features can lead to the accumulation of pollutants and worsen air quality (Danek, Weglinska and Zareba, 2022).\n\n\n\nPM2.5 emissions (New York City Comptroller, n/d)\n\n\n\n\n\nO3 emissions (New York City Comptroller, n/d)\n\n\nOneNYC 2050 (New York City’s climate team, n/d) is a comprehensive sustainability plan introduced by the City of New York to address various challenges faced by the city, including environmental issues like air pollution. The plan encompasses initiatives aimed at reducing greenhouse gas emissions, improving air quality, and enhancing overall sustainability in the city.\nOneNYC 2050 addresses air pollution challenges in New York City through a range of policies and strategies designed to mitigate pollution sources, improve air quality monitoring, and promote public health. Including the following aspects:\n\nTraffic Emissions Reduction: Implementing measures to reduce vehicle emissions, and implementing congestion pricing to decrease traffic-related pollution.\nIndustrial Emission Controls: Enforcing regulations and incentives to reduce emissions from industrial sources like factories and power plants to enhance air quality and protect public health.\nGreen Infrastructure Development: Encouraging the creation of green spaces, urban forests, and sustainable infrastructure to help absorb pollutants and improve overall air quality in the city.\nPublic Awareness Campaigns: Educating residents about the health risks associated with air pollution and encouraging behavior changes that contribute to cleaner air and healthier communities.\n\nIn addition, the United Nations Environment Program released the report “Actions on Air Quality: A Global Summary of Policies and Programs to Reduce Air Pollution” (Environment, Fri, 09/03/2021 - 10:01) with the purpose of preventing and reducing air pollution to improve global air quality. It builds on the United Nations Environment Program (UNEP) 2016 report Action on Air Quality (Environment, Sun, 01/31/2016 - 00:00), which focuses on a range of measures to significantly improve air quality. World Health Organization (WHO) guidelines (World Health Organization, n/d) also provide guidance and recommendations on air quality standards to protect public health. It aims to reduce exposure to harmful air pollutants and mitigate the health impacts of poor air quality on populations around the world."
  },
  {
    "objectID": "Week_4.html#applications",
    "href": "Week_4.html#applications",
    "title": "4  Week 4 - Policy applications",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nRemote sensing data offers innovative solutions for monitoring and managing air pollution effectively.\n\nAir Pollution Risk Assessment Conduct air pollution risk assessments using GIS and remotely sensed data, as demonstrated in Kirkuk City, Iraq (Jamal Jumaah et al., 2023). Utilize geo-statistic techniques to map Air Quality Index (AQI) and Particulate Matter (PM10 and PM2.5) concentrations. Analyze remotely sensed data of PM2.5 and compare it with field measurements to assess health impacts per air pollutant. Generate spatial distribution maps to identify areas with hazardous air quality levels and provide insights for targeted interventions to mitigate pollution-related health risks.\nEarth observation technology Earth observation (EO), including remote sensing, provides novel methods for estimating the annual mean levels of fine particulate matter (PM2.5) in cities. The H2020 SMURBS/ERA-PLANET project demonstrates the use of Copernicus Atmospheric Monitoring Service reanalysis data for PM2.5 values, offering a more granular and harmonized global approach to air quality monitoring (Bailey et al., 2023). This enables better comparability and scalability in monitoring efforts, which is essential for effective policy implementation and air pollution management.\nMonitoring and Management Platform Development Develop a near real-time air pollution monitoring platform. The development of platforms like “Life Dee” in Thailand for near real-time monitoring of PM2.5 concentrations showcases the potential of combining remote sensing data, ground-based stations, and microclimate modeling (Sukawattanavijit et al., 2023). Such platforms provide a user-friendly interface for the public to monitor air quality and receive information on protective measures. They also offer valuable insights for government agencies to take proactive steps in mitigating air pollution and improving public health."
  },
  {
    "objectID": "Week_4.html#reflections",
    "href": "Week_4.html#reflections",
    "title": "4  Week 4 - Policy applications",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nPolicies play a crucial role in shaping the development and functioning of cities. Proper policies can move urban areas toward more sustainable development. The use of data in policy-making can lead to more informed decisions. By analyzing data related to various aspects of city life, policymakers can identify trends, assess the effectiveness of policies, and make evidence-based choices.In addition, attention needs to be paid to data privacy issues and digital divide issues as well as ensuring equitable access to benefits when applying data to address policy challenges.\nAddressing complex urban issues requires an interdisciplinary approach that integrates knowledge from various fields such as urban planning, data science, public policy, and social sciences. Collaboration across disciplines can lead to more holistic solutions. Involving residents in decision-making processes is essential for effective policy implementation in cities. Engaging with communities through data-driven approaches can help in understanding their needs and preferences better. Given the dynamic nature of cities and policies, it is important to continuously learn from experiences, adapt strategies based on feedback and data insights, and iterate on solutions to address evolving challenges.\n\n\n\n\nBailey, J. et al. (2023) “Localizing SDG 11.6.2 via Earth Observation, Modelling Applications, and Harmonised City Definitions: Policy Implications on Addressing Air Pollution,” Remote Sensing, 15(4), p. 1082. doi: 10.3390/rs15041082.\n\n\nDanek, T., Weglinska, E. and Zareba, M. (2022) “The influence of meteorological factors and terrain on air pollution concentration and migration: A geostatistical case study from Krakow, Poland,” Scientific Reports, 12(1), p. 11050. doi: 10.1038/s41598-022-15160-3.\n\n\nEnvironment, U. N. (Fri, 09/03/2021 - 10:01) “Actions on Air Quality: A Global Summary of Policies and Programmes to Reduce Air Pollution,” UNEP - UN Environment Programme. Available at: http://www.unep.org/resources/report/actions-air-quality-global-summary-policies-and-programmes-reduce-air-pollution (Accessed: March 3, 2024).\n\n\nEnvironment, U. N. (Sun, 01/31/2016 - 00:00) “Actions on Air Quality,” UNEP - UN Environment Programme. Available at: http://www.unep.org/resources/assessment/actions-air-quality (Accessed: March 3, 2024).\n\n\nGreenfield, D. E. (2023) “New York Air Quality: Challenges And Solutions,” Sigma Earth. Available at: https://sigmaearth.com/new-york-air-quality-challenges-and-solutions/ (Accessed: March 3, 2024).\n\n\nJamal Jumaah, H. et al. (2023) “Air Pollution Risk Assessment Using GIS and Remotely Sensed Data in Kirkuk City, Iraq,” Journal of Atmospheric Science Research, 6(3), pp. 41–51. doi: 10.30564/jasr.v6i3.5834.\n\n\nNew York City Comptroller (n/d) “Emissions,” Office of the New York City Comptroller Brad Lander. Available at: https://comptroller.nyc.gov/services/for-the-public/nyc-climate-dashboard/emissions/ (Accessed: March 4, 2024).\n\n\nNew York City’s climate team (n/d) “OneNYC 2050,” NYC Mayor’s Office of Climate and Environmental Justice. Available at: https://climate.cityofnewyork.us/reports/onenyc-2050/ (Accessed: March 3, 2024).\n\n\nSukawattanavijit, C. et al. (2023) “The future of urban air quality management in Thailand: The cutting-edge platform for monitoring and management of public health and sustainable development,” in Chrysoulakis, N., Erbertseder, T., and Zhang, Y. (eds.) Remote Sensing Technologies and Applications in Urban Environments VIII. Amsterdam, Netherlands: SPIE, p. 19. doi: 10.1117/12.2679297.\n\n\nWorld Health Organization (n/d) “WHO Guidelines.” Available at: https://www.who.int/publications/who-guidelines (Accessed: March 3, 2024)."
  },
  {
    "objectID": "Week_5.html#summary",
    "href": "Week_5.html#summary",
    "title": "5  Week 5 - An introduction to Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week I learned Google Earth Engine (GEE). The main content includes GEE basic knowledge and applications. The key application direction is reducing images and image enhancement. The biggest benefit of using GEE is that it speeds up all processes of analysis. The knowledge points will be briefly summarized below.\n\n5.1.1 Google Earth Engine (GEE)\nGoogle Earth Engine is a cloud-based platform developed by Google for planetary-scale environmental data analysis (Google, n/d). It allows users to access a vast amount of geospatial data, including satellite imagery, and perform complex analyses using Google’s computational resources.\nGEE uses Javascript (a Website programming language) or Python (sometimes).\n\n\n5.1.2 Client and server side\nGeospatial analysis from the client is converted into Earth Engine requests. Earth Engine objects need to be distinguished from other JavaScript objects or primitives (Google for Developers, n/d).\n\nLooping: server-side mapping\nConditionals: server-side conditional\n\n\n\n\nClient side vs Server side (Hawkins, 2018)\n\n\n\n\n5.1.3 GEE in action\n\n5.1.3.1 Reducing images\n\nee.Reducer can reduce a collection of images to the extreme value of each pixel\nreduceRegion() is used to reduce images by region\nreduceNeighborhood() is used to reduce the image by neighborhood (A window of pixels/kernel)\n\n\n\n5.1.3.2 Linear regression\nSeveral methods for performing linear regression using reducers:\n\nee.Reducer.linearFit()\nee.Reducer.linearRegression()\nee.Reducer.robustLinearRegression()\nee.Reducer.ridgeRegression()\n\nPurpose: View the change over time in pixel values.\n\n\n5.1.3.3 Joins (use ee.Filter)\n\njoin image collections\njoin feature collections\nspatial join, intersect, subset\n\n\n\n\n5.1.4 Practical\nThis week’s exercises will focus on reducing images and image enhancement. Reducing images can quickly reduce a collection of images to a single image using the mean, median, maximum or minimum value for further analysis. Image enhancement involves NDVI, texture measures and PCA. When the study area is large, the results of these methods can be obtained faster using GEE.\n\n\n\nNDVI results using GEE\n\n\nThis is the NDVI result using Landsat8 images from June 2021 to October 2022, and the study area is the entire Dehli area. The result clearly show that there is less vegetation coverage near the center of the region, while some small areas with more vegetation coverage appear in the south. These small areas may be nature reserves or parks.\n\n\n\nTexture measure results using GEE\n\n\nThis is the GLCM (Gray-level co-occurrence matrix) texture measure results of the same image. The results show some obvious areas, including airports, industrial areas, etc. These areas are scattered around the edges.\n\n\n\nPCA numerical results\n\n\n\n\n\nPCA results using GEE (component 1 and 2)\n\n\nFrom the numerical results, it can be found that the first component explains 80% of the variance and the second component explains 13% of the variance. These two components are the most critical for the image collection. The combined image from these two components also contains most important information, such as rivers, airports, industrial areas, etc."
  },
  {
    "objectID": "Week_5.html#applications",
    "href": "Week_5.html#applications",
    "title": "5  Week 5 - An introduction to Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nGEE is a powerful platform that leverages cloud computing to process and analyze vast amounts of Earth observation data for various applications, including remote sensing. Remote sensing applications of GEE span across monitoring environmental changes, agricultural operations, geological activities, and more (Pham-Duc et al., 2023).\nThere are some notable achievements in water body research. One group of researchers developed an application for mapping inland water bodies in the country of Turkey using remote sensing data integrated into Google Earth Engine (GEE) (Atay and Kaplan, 2023). It shows that GEE is a promising application for processing large amounts of satellite data.\nAnother group of researchers used Google Earth Engine (GEE) for mapping national inland water bodies in Croatia (Gašparović, 2022). And the results showed that GEE is also a very successful application for handling big satellite data and can accurately extract water bodies on a national level.\nIn addition, a group of researchers explored the possibility of using the Google Earth Engine (GEE) platform for mapping the Trophic State Index (TSI) of an inland water body (Sherjah, Sajikumar and Nowshaja, 2023). This study illustrates that GEE can quickly help us understand a period of time. Water quality of lakes and rivers over time.\nOf course, GEE also has some limitations. Although GEE provides access to large amounts of geospatial data, but it does not have the data that users need, and the quality of the data it provides may vary. Additionally, processing times may vary depending on the complexity of the analysis and the size of the data. Some analyzes can also take a lot of time.\nOne study used GEE to monitor the reconstruction of Leyte Island in the Philippines after a disaster (Ghaffarian, Rezaie Farhadabad and Kerle, 2020). This study shows that while Google Earth Engine is useful for viewing large areas, it is less suitable for viewing the details of cities because it does not have very high-resolution imagery."
  },
  {
    "objectID": "Week_5.html#reflections",
    "href": "Week_5.html#reflections",
    "title": "5  Week 5 - An introduction to Google Earth Engine",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nI came across GEE this week and I have to admit that GEE saves a lot of time and has ample remote sensing data. GEE has already completed the work of storing data and configuring the development environment for me. I only need to think about what data I need and what methods to solve the problem, and then use GEE to quickly analyze. Although I spent a lot of time in the initial learning process of GEE and was not very comfortable with new tools, once I understood the entire workflow, GEE brought me great convenience.\nThe development method using GEE is also different from the R language that was familiar before. In addition to the Javascript language, it requires users to establish a server-side development mentality. This therefore requires a change in the way you think about daily programming. However, the GEE instruction manual contains a large number of detailed tutorials with application examples, which is also helpful for beginners to learn.\nIn addition, I feel that the way GEE presents analysis results pays more attention to the interaction process with users. We can view the analysis results using an interactive map. And there are already many great interactive applications, which also help users intuitively view and compare different results.\n\n\n\n\nAtay, M. A. and Kaplan, G. (2023) “Large-Scale Mapping of Inland Waters with Google Earth Engine Using Remote Sensing,” Environmental Sciences Proceedings, 25(1), p. 52. doi: 10.3390/ECWS-7-14171.\n\n\nGašparović, G. K., Mateo (2022) “Large-Scale Mapping and Monitoring Inland Waters by Google Earth Engine and Remote Sensing Techniques,” in Geospatial Information Handbook for Water Resources and Watershed Management, Volume I. CRC Press.\n\n\nGhaffarian, S., Rezaie Farhadabad, A. and Kerle, N. (2020) “Post-Disaster Recovery Monitoring with Google Earth Engine,” Applied Sciences, 10(13), p. 4574. doi: 10.3390/app10134574.\n\n\nGoogle (n/d) “Google Earth Engine.” Available at: https://earthengine.google.com (Accessed: March 4, 2024).\n\n\nGoogle for Developers (n/d) “Client vs. Server  Google Earth Engine  Google for Developers.” Available at: https://developers.google.com/earth-engine/guides/client_server (Accessed: March 4, 2024).\n\n\nHawkins, L. (2018) “Server-Side vs Client-Side Programming Languages,” Tech Web Space. Available at: https://www.techwebspace.com/server-side-vs-client-side-programming-languages/ (Accessed: March 4, 2024).\n\n\nPham-Duc, B. et al. (2023) “Trends and applications of google earth engine in remote sensing and earth science research: A bibliometric analysis using scopus database,” Earth Science Informatics, 16(3), pp. 2355–2371. doi: 10.1007/s12145-023-01035-2.\n\n\nSherjah, P. Y., Sajikumar, N. and Nowshaja, P. T. (2023) “Quality monitoring of inland water bodies using Google Earth Engine,” Journal of Hydroinformatics, 25(2), pp. 432–450. doi: 10.2166/hydro.2023.137."
  }
]