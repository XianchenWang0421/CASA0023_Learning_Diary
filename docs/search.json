[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction\nThis is the learning diary of the CASA0023 (Remotely Sensing Cities and Environments)."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n2  Introduction\n",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Jensen, J. R. (2015) Introductory Digital Image\nProcessing: A Remote Sensing Perspective. 4th\nedn. USA: Prentice Hall Press.\n\n\nThe Nature Conservancy (n/d) ‘What is Remote Sensing?\n Reef Resilience’. Available at: https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/\n(Accessed: 3 February 2024)."
  },
  {
    "objectID": "Week_2.html#presentation",
    "href": "Week_2.html#presentation",
    "title": "\n2  Week 2 - Portfolio tools: Quarto\n",
    "section": "\n2.1 Presentation",
    "text": "2.1 Presentation"
  },
  {
    "objectID": "Week_1.html#summary",
    "href": "Week_1.html#summary",
    "title": "1  Week 1 - An Introduction to Remote Sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\nThis section will summarize the content of first week of remote sensing course, which is some basic remote sensing knowledge, including how to obtain remote sensing images, image features, etc. Some key points are listed below.\n\n1.1.1 Overview of remote sensing\nRemote sensing is a technology that senses and measures information on the earth’s surface over long distances. It is now frequently used to obtain accurate and timely information, and most remote sensing data are analyzed using digital image processing techniques (Jensen, 2015).\n\n\n1.1.2 Sensor types\n\nPassive: Receive energy reflected from the sun\nActive: Actively emits electromagnetic waves and then waits to receive\n\n\n\n\nDifference between passive and active sensors (The Nature Conservancy, n/d)\n\n\n\n\n1.1.3 Electromagnetic radiation(EMR) interacts with Earth’s surface\nEnergy can be absorbed and transmitted.\nTwo forms:\n\nSurface scattering\nAtmospheric scattering\n\n\n\n1.1.4 Big issue caused by scattering\n\n1.1.4.1 Problem\nClouds: Impact on remote sensing applications\n\n\n1.1.4.2 Solution\nSynthetic Aperture Radar (SAR)\n\nIt is an active microwave remote sensing technology\nIt is not limited by weather conditions, cloud cover, or nighttime\nValuable for geological exploration, land use monitoring, disaster assessment\n\n\n\n1.1.4.3 Conclusion\nThe sun’s energy interacts with the Earth’s surface in many ways, affecting the creation and use of data.\n\n\n\n1.1.5 Remote sensing data\n\n1.1.5.1 Data formats\n\nData format: Raster\nCommon data storage format: GeoTIFF\n\n\n\n1.1.5.2 Data resolution\n\nSpatial: The size of the raster cells\nSpectral: The number of bands, and each band is usually provided as a separate raster layer\nTemporal: The revisit time of the sensor\nRadiometric: The ability of a sensor to identify and show small differences in energy\n\n\n\n\n1.1.6 How to select data\n\nEnvironmental constraints\n\nResearch area\nResearch question\nresearch Fund (cost)\n…\n\nSensor constraints\n\nSize of features\nSpectral sensitivity\nDate range\nQuality of the image\nType of orbit\n…\n\n\n\n\n1.1.7 Practical\n\n1.1.7.1 Use Tasseled Cap transformation for analysis\n\nTasseled Cap function\n\n\\[\n\\begin{split}\nBrightness = 0.3037(B2)+0.2793(B3)+\\\\0.4743(B4)+0.5585(B8)+\\\\\n0.5082(B11)+0.1863(B12)\n\\end{split}\n\\]\n\\[\n\\begin{split}\nGreeness = −0.2848(B2)−0.2435(B3)\\\\−0.5436(B4)+0.7243(B8)+\\\\\n0.0840(B11)−0.1800(B12)\n\\end{split}\n\\]\n\\[\n\\begin{split}\nWetness = 0.1509(B2)+0.1973(B3)\\\\+0.3279(B4)+0.3406(B8)\\\\−\n0.7112(B11)−0.4572(B12)\n\\end{split}\n\\]\n\nMasking and resampling\n\n\nResample bands 2,3,4 and 8 to 20m\nClip the raster to the City of Capetown polygon\n\n\nResult\n\n\n\n\nTasseled Cap transformation result\n\n\nIt can be found from the figure:\n\nBrightness reflects bare soil, artificial surfaces, bright materials\nGreenness reflects green vegetation\nWetness reflects moisture\n\n\n\n1.1.7.2 Spectral signatures of POIs\nLand cover types of POIs:\n\nBare earth\ngrass\nForest\nHigher reflective urban\nLower reflective urban\n\n\n\n\nA: Line graph of spectral characteristics B: Density distribution plot of spectral features\n\n\nIt can be seen from the results that different POIs have different performances on different bands, and high urban has a larger difference than other POIs. Specific areas can be detected or classified through differences in band values in different areas, or by combining the values of several bands."
  },
  {
    "objectID": "Week_1.html#applications",
    "href": "Week_1.html#applications",
    "title": "1  Week 1 - An Introduction to Remote Sensing",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nIn the first week of study, I am most interested in Tasseled Cap transformation (TCT). It converts spectral information in remote sensing images into brightness, greenness, and wetness components, which can be applied in many fields.\nSpecifically, TCT can help extract water bodies by obtaining the greenness and wetness components of remote sensing images, and can reduce the impact of shadows, dense vegetation and buildings (Zhuang and Chen, 2018; Chen et al., 2020, 2022). By considering the characteristics of coastline morphology and the greenness and wetness components, the TCT can also be used to extract coastline information, particularly in areas with high sediment concentration (Chen et al., 2019).One study (Wang and Zhu, 2003) compared the TCT method with a Learning Vector Quantization (LVQ) neural network and a conventional rule-based method for water body extraction from Landsat 4 satellite images. It was found that the error of thresholding on the wetness in the TCT method is too large to be practical for this purpose. This suggests that while TCT can be useful for various remote sensing applications, its effectiveness for water body extraction may be limited under certain conditions or compared to other specialized methods.\nComponents of TCT, such as brightness, greenness, and wetness, can provide valuable information about the condition and changes in forest vegetation over time (Liu, 2019b, 2019a; Stoyanov, 2022), also monitor the health of the forest (Liu and Liu, 2009). But the TCT parameters need to be recalculated for different sensors or spectral data, enabling more accurate classification of vegetation patches, crop types, and changes in forest health. Moreover, an innovative approach involved modeling post-fire forest regrowth using TCT-derived indicators (Stankova and Avetisyan, 2023). This methodology leverages the TCT to increase the identification of components (soil, vegetation, and moisture) changing during a fire, thereby providing a cost-effective tool for monitoring the recovery of burnt forests."
  },
  {
    "objectID": "Week_1.html#reflections",
    "href": "Week_1.html#reflections",
    "title": "1  Week 1 - An Introduction to Remote Sensing",
    "section": "1.3 Reflections",
    "text": "1.3 Reflections\nOverall, the first week was heavy and covered many basic concepts of remote sensing data, but it was not difficult in terms of understanding. These basics were important to me as a beginner in remote sensing because it gave me a clear understanding of the sources and structure of remotely sensed data and laid the foundation for subsequent courses. Although I was a bit overwhelmed when I first came across SNAP as a software, with a little bit of research on remote sensing data, I successfully used SNAP to get satisfactory analysis results. In addition, thanks to the emergence of packages such as stars and terra, it is easier and faster to analyse a large amount of remote sensing data in a unified way using R language, and the results can be presented in a more beautiful way. Therefore, for me personally, I prefer to use R for analyses.\n\n\n\n\nChen, C. et al. (2019) “Coastline information extraction based on the tasseled cap transformation of Landsat-8 OLI images,” Estuarine, Coastal and Shelf Science, 217, pp. 281–291. doi: 10.1016/j.ecss.2018.10.021.\n\n\nChen, C. et al. (2020) “The method for water body information extraction in complex environment using GF-1 WFV images,” E3S Web of Conferences, 213, p. 03024. doi: 10.1051/e3sconf/202021303024.\n\n\nChen, C. et al. (2022) “Extraction of Water Body Information from Remote Sensing Imagery While Considering Greenness and Wetness Based on Tasseled Cap Transformation,” Remote Sensing, 14(13), p. 3001. doi: 10.3390/rs14133001.\n\n\nJensen, J. R. (2015) Introductory Digital Image Processing: A Remote Sensing Perspective. 4th ed. USA: Prentice Hall Press.\n\n\nLiu, Q. (2019a) “A tasseled cap transformation for CBERS-04 fusion multispectral images,” in Eleventh International Conference on Digital Image Processing (ICDIP 2019). SPIE, pp. 730–736. doi: 10.1117/12.2539649.\n\n\nLiu, Q. (2019b) “A Tasseled Cap Transformation for GF-2 Fused Multispectral Images,” in 2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI), pp. 1–5. doi: 10.1109/CISP-BMEI48845.2019.8966053.\n\n\nLiu, Q. and Liu, G. (2009) “Using Tasseled Cap Transformation of CBERS-02 Images to Detect Dieback or Dead Robinia Pseudoacacia Plantation,” in 2009 2nd International Congress on Image and Signal Processing, pp. 1–5. doi: 10.1109/CISP.2009.5304005.\n\n\nStankova, N. and Avetisyan, D. (2023) “Modeling post-fire forest regrowth using tasseled cap-derived indicators,” in Schulz, K., Nikolakopoulos, K. G., and Michel, U. (eds.) Earth Resources and Environmental Remote Sensing/GIS Applications XIV. Amsterdam, Netherlands: SPIE, p. 54. doi: 10.1117/12.2679783.\n\n\nStoyanov, A. (2022) “Application of Tasseled Cap Transformation of Sentinel-2—MSI Data for Forest Monitoring and Change Detection on Territory of Natural Park ‘BLUE STONES’,” Environmental Sciences Proceedings, 22(1), p. 42. doi: 10.3390/IECF2022-13073.\n\n\nThe Nature Conservancy (n/d) “What is Remote Sensing?  Reef Resilience.” Available at: https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/ (Accessed: February 3, 2024).\n\n\nWang, K. and Zhu, Y. (2003) “Recognition of Water Bodies from Remotely Sensed Imagery by Using Neural Network,” in. Available at: https://www.semanticscholar.org/paper/Recognition-of-Water-Bodies-from-Remotely-Sensed-by-Wang-Zhu/e9bfbfb9b558e0fccb5f49a51fdc24d558bef220 (Accessed: March 3, 2024).\n\n\nZhuang, Y. and Chen, C. (2018) “A Method for water body extraction based on the tasselled cap transformation from remote sensing images,” in 2018 Fifth International Workshop on Earth Observation and Remote Sensing Applications (EORSA), pp. 1–5. doi: 10.1109/EORSA.2018.8598605."
  },
  {
    "objectID": "references.html#section",
    "href": "references.html#section",
    "title": "References",
    "section": "",
    "text": "Jensen, J. R. (2015) Introductory digital image processing: A remote\nsensing perspective. 4th edn. USA: Prentice Hall Press.\n\n\nThe Nature Conservancy (n/d) ‘What is Remote Sensing?\n Reef Resilience’. Available at: https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/\n(Accessed: 3 February 2024)."
  },
  {
    "objectID": "Week_3.html#summary",
    "href": "Week_3.html#summary",
    "title": "3  Week 3 - Remote sensing data",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Corrections\n\n3.1.1.1 Geometric correction\nTwo ways modelling:\n\nInput to output (forward mapping)\nOutput to input (backward mapping)\n\nWe usually use backward mapping, because every value in the output pixel can get a value in the original input image.\n\n\n3.1.1.2 Atmospheric correction\n\nDark object subtraction (DOS) or histogram adjustment\nPsuedo-invariant Features (PIFs)\nChange digital brightness values into scaled surface reflectance.\nEmpirical line correction\n\n\n\n3.1.1.3 Orthorectification correction / topographic correction\n\nA subset of georectification\nRemoving distortions\nAtmospheric correction happens before topographic correction\n\n\n\n3.1.1.4 Radiometric calibration\n\nSensors capture image brightness and distributed as a Digital Number (DN, and no units)\nRadiometric calibration = DN to spectral radiance\n\n\n\n3.1.1.5 Analysis ready data (ARD)\nRemote sensing data has been corrected (like Landsat data).\n\n\n\n3.1.2 Data joining and enhancement\n\n3.1.2.1 Joining data sets\n“Mosaicking” in remote sensing: feather the images together to create a seamless mosaic or image.\n\n\n3.1.2.2 Image enhancement\n\nContrast enhancement methods (only applied to digital numbers)\n\nMinimum - Maximum\nPercentage Linear and Standard Deviation\nPiecewise Linear Contrast Stretch\n\nBand ratioing methods\n\nNDVI\nTasselled cap\nNormalized Burn Ratio\n\nFiltering\n\nLow pass filter (averages the surrounding pixels)\nHigh pass filter (enhance local variations)\nEdge enhancement (image sharpening)\n\nPrincipal component (dimensionatliy reduction)\nTexture (spatial variation of gray values)\nFusion"
  },
  {
    "objectID": "Week_3.html#applications",
    "href": "Week_3.html#applications",
    "title": "3  Week 3 - Remote sensing data",
    "section": "3.2 Applications",
    "text": "3.2 Applications"
  },
  {
    "objectID": "Week_3.html#reflections",
    "href": "Week_3.html#reflections",
    "title": "3  Week 3 - Remote sensing data",
    "section": "3.3 Reflections",
    "text": "3.3 Reflections"
  }
]